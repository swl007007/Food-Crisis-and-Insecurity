{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import datetime\n",
    "\n",
    "# read csv file\n",
    "location = pd.read_csv(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\(2) prepare for the new dataset\\intermediate\\geometry.csv')\n",
    "# unique the dataframe based on year_month and geometry\n",
    "location = location.drop_duplicates(subset=['year_month', 'geometry'], keep='first')\n",
    "# Read in the data\n",
    "areas_gdf = gpd.read_file(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\CHIRPS\\chirps_1.geojson')\n",
    "areas_gdf_2 = gpd.read_file(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\CHIRPS\\chirps_2.geojson')\n",
    "areas_gdf_3 = gpd.read_file(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\CHIRPS\\chirps_3.geojson')\n",
    "areas_gdf_4 = gpd.read_file(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\CHIRPS\\chirps_4.geojson')\n",
    "\n",
    "\n",
    "merged_gdf = pd.concat([areas_gdf, areas_gdf_2, areas_gdf_3, areas_gdf_4])\n",
    "\n",
    "\n",
    "import re\n",
    "gdf = merged_gdf\n",
    "def extract_year_month(file_name):\n",
    "    pattern = r\"(\\d{4})\\.(\\d{2})\"\n",
    "    match = re.search(pattern, file_name)\n",
    "\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        month = int(match.group(2))\n",
    "        return year, month\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Use the apply method to apply the function to the 'file_name' column\n",
    "gdf['year_month'] = gdf['time'].apply(extract_year_month)\n",
    "\n",
    "# Split the 'year_month' tuple into separate 'year' and 'month' columns\n",
    "gdf[['year', 'month']] = gdf['year_month'].apply(pd.Series)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop the 'year_month', 'time', 'year' and 'month' columns\n",
    "gdf['date'] = pd.to_datetime(gdf[['year', 'month']].assign(DAY=1))\n",
    "gdf.drop(columns='year_month', inplace=True)\n",
    "gdf.drop(columns='time', inplace=True)\n",
    "gdf.drop(columns='year', inplace=True)\n",
    "gdf.drop(columns='month', inplace=True)\n",
    "\n",
    "# drop FID, rename value as rainfall_chirps.\n",
    "gdf.drop(columns='FID', inplace=True)\n",
    "gdf.rename(columns={'value': 'rainfall_chirps'}, inplace=True)\n",
    "\n",
    "# rearrange the columns\n",
    "gdf = gdf[['date', 'geometry','rainfall_chirps']]\n",
    "# see the number of unique geometry date pairs\n",
    "gdf.drop_duplicates(subset=['date', 'geometry'], keep='first')\n",
    "# split into a list of dataframes based on date\n",
    "gdf_list = [g for _, g in gdf.groupby('date')]\n",
    "\n",
    "# convert the geometry column in each data frame to string and loop over the list\n",
    "for i in tqdm.tqdm(range(len(gdf_list))):\n",
    "    gdf_list[i]['geometry'] = gdf_list[i]['geometry'].astype(str)\n",
    "\n",
    "# concat the list of dataframes into one dataframe\n",
    "gdf_new = pd.concat(gdf_list)\n",
    "# rename year_month as date\n",
    "location.rename(columns={'year_month': 'date'}, inplace=True)\n",
    "\n",
    "# parse date column in location dataframe as datetime\n",
    "location['date'] = pd.to_datetime(location['date'])\n",
    "# merge two dataframes based on date and geometry\n",
    "merged = pd.merge(location, gdf_new, on=['date', 'geometry'], how='left')\n",
    "# read csv file\n",
    "original = pd.read_csv(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\(2) prepare for the new dataset\\intermediate\\ACLED_GOSIF_GPP_mean.csv')\n",
    "# check dtypes\n",
    "original.dtypes\n",
    "# check merged dtypes\n",
    "merged.dtypes\n",
    "# rename year_month in original dataframe as date\n",
    "original.rename(columns={'year_month': 'date'}, inplace=True)   \n",
    "\n",
    "# parse date column in original dataframe as datetime\n",
    "original['date'] = pd.to_datetime(original['date'])\n",
    "# merge two dataframes based on date and geometry\n",
    "merged_2 = pd.merge(original, merged, on=['date', 'geometry'], how='left')\n",
    "# save merged_2 as csv file\n",
    "merged_2.to_csv(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\(2) prepare for the new dataset\\intermediate\\ACLED_GOSIF_GPP_CHIRPS.csv', index=False)\n",
    "# clear memory, only keep merged_2\n",
    "del original, merged, merged_2, gdf, gdf_list, gdf_new, areas_gdf, areas_gdf_2, areas_gdf_3, areas_gdf_4, location\n",
    "\n",
    "# Read in the data\n",
    "areas_gdf = gpd.read_file(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\GOSIF_GPP_SD\\GOSIF_GPP_SD_1.geojson')\n",
    "areas_gdf_2 = gpd.read_file(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\GOSIF_GPP_SD\\GOSIF_GPP_SD_2.geojson')\n",
    "areas_gdf_3 = gpd.read_file(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\GOSIF_GPP_SD\\GOSIF_GPP_SD_3.geojson')\n",
    "areas_gdf_4 = gpd.read_file(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\GOSIF_GPP_SD\\GOSIF_GPP_SD_4.geojson')\n",
    "\n",
    "\n",
    "merged_gdf = pd.concat([areas_gdf, areas_gdf_2, areas_gdf_3, areas_gdf_4])\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "gdf = merged_gdf\n",
    "def extract_year_month(file_name):\n",
    "    pattern = r\"(\\d{4})\\.M(\\d{2})\"\n",
    "    match = re.search(pattern, file_name)\n",
    "\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        month = int(match.group(2))\n",
    "        return year, month\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Use the apply method to apply the function to the 'file_name' column\n",
    "gdf['year_month'] = gdf['time'].apply(extract_year_month)\n",
    "\n",
    "# Split the 'year_month' tuple into separate 'year' and 'month' columns\n",
    "gdf[['year', 'month']] = gdf['year_month'].apply(pd.Series)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop the 'year_month', 'time', 'year' and 'month' columns\n",
    "gdf['date'] = pd.to_datetime(gdf[['year', 'month']].assign(DAY=1))\n",
    "gdf.drop(columns='year_month', inplace=True)\n",
    "gdf.drop(columns='time', inplace=True)\n",
    "gdf.drop(columns='year', inplace=True)\n",
    "gdf.drop(columns='month', inplace=True)\n",
    "\n",
    "\n",
    "# drop FID, rename value as rainfall_chirps.\n",
    "gdf.drop(columns='FID', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rearrange the columns\n",
    "gdf = gdf[['date', 'geometry','GOSIF_GPP_SD']]\n",
    "# see the number of unique geometry date pairs\n",
    "gdf.drop_duplicates(subset=['date', 'geometry'], keep='first')\n",
    "\n",
    "\n",
    "# split into a list of dataframes based on date\n",
    "gdf_list = [g for _, g in gdf.groupby('date')]\n",
    "\n",
    "# convert the geometry column in each data frame to string and loop over the list\n",
    "for i in tqdm.tqdm(range(len(gdf_list))):\n",
    "    gdf_list[i]['geometry'] = gdf_list[i]['geometry'].astype(str)\n",
    "\n",
    "# concat the list of dataframes into one dataframe\n",
    "gdf_new = pd.concat(gdf_list)\n",
    "\n",
    "# read csv file\n",
    "original = pd.read_csv(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\(2) prepare for the new dataset\\intermediate\\ACLED_GOSIF_GPP_CHIRPS.csv')\n",
    "# convert date column to datetime\n",
    "original['date'] = pd.to_datetime(original['date'])\n",
    "original.dtypes\n",
    "gdf_new.dtypes\n",
    "# merge two dataframes based on date and geometry\n",
    "merged_2 = pd.merge(original, gdf_new, on=['date', 'geometry'], how='left')\n",
    "# save merged_2 as csv file\n",
    "merged_2.to_csv(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\(2) prepare for the new dataset\\intermediate\\ACLED_GOSIF_GPP_CHIRPS_GOSIF_GPP_SD.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
