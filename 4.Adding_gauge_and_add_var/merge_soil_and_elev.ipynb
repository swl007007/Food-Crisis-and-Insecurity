{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import new_merge.csv\n",
    "df = pd.read_csv(r'.\\intermediate\\new_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import soil\n",
    "soil = pd.read_csv(r'.\\intermediate\\soil_moisture_0_to_7cm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "soil['date'] = pd.to_datetime(soil['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename lat_x as lat and lon_x as lon\n",
    "df.rename(columns={'lat_x': 'lat', 'lon_x': 'lon'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# check if date lat lon form a unique key\n",
    "print(df.groupby(['date', 'lat', 'lon']).size().max())\n",
    "print(soil.groupby(['date', 'lat', 'lon']).size().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df and soil, left on date, lat, lon, add indicator\n",
    "df = df.merge(soil, how='left', on=['date', 'lat', 'lon'], indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_merge\n",
      "left_only         0\n",
      "right_only        0\n",
      "both          38776\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# see merge result\n",
    "print(df.groupby('_merge').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop _merge\n",
    "df.drop('_merge', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to csv\n",
    "df.to_csv('merge_complete_soil.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique lat lon\n",
    "lat_lon = df[['lat', 'lon']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.533893</td>\n",
       "      <td>14.070903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.493558</td>\n",
       "      <td>14.068317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.289988</td>\n",
       "      <td>14.314904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.765411</td>\n",
       "      <td>15.778695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.248169</td>\n",
       "      <td>16.437358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37994</th>\n",
       "      <td>-13.463138</td>\n",
       "      <td>38.398858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38002</th>\n",
       "      <td>-13.465048</td>\n",
       "      <td>38.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38150</th>\n",
       "      <td>3.426228</td>\n",
       "      <td>46.034461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38483</th>\n",
       "      <td>-13.570206</td>\n",
       "      <td>33.788265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38751</th>\n",
       "      <td>31.576524</td>\n",
       "      <td>70.151667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lat        lon\n",
       "0      -5.533893  14.070903\n",
       "1      -5.493558  14.068317\n",
       "2      -5.289988  14.314904\n",
       "3       6.765411  15.778695\n",
       "4       7.248169  16.437358\n",
       "...          ...        ...\n",
       "37994 -13.463138  38.398858\n",
       "38002 -13.465048  38.406667\n",
       "38150   3.426228  46.034461\n",
       "38483 -13.570206  33.788265\n",
       "38751  31.576524  70.151667\n",
       "\n",
       "[1878 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1878/1878 [04:46<00:00,  6.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "\n",
    "\n",
    "# create a new df to store the data\n",
    "result = pd.DataFrame(columns=['lat', 'lon', 'elevation'])\n",
    "\n",
    "# loop through each lat and lon\n",
    "for i in tqdm.tqdm(range(len(lat_lon))):\n",
    "    # request the data from the API\n",
    "    url = 'https://api.open-meteo.com/v1/elevation?latitude=' + str(lat_lon['lat'].iloc[i]) + '&longitude=' + str(lat_lon['lon'].iloc[i])\n",
    "    try:\n",
    "        response = requests_retry_session().get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"Http Error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"Error Connecting:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"Timeout Error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"OOps: Something Else\",err)\n",
    "    data = response.json()\n",
    "    # create a new df to store the data\n",
    "    df = pd.DataFrame(columns=['lat', 'lon', 'elevation'])\n",
    "    # extract time and temperature_2m_mean from the json file\n",
    "    if 'elevation' in data:\n",
    "        df['elevation'] = data['elevation']\n",
    "    else:\n",
    "        df['elevation'] = np.nan\n",
    "    df['lat'] = lat_lon['lat'].iloc[i]\n",
    "    df['lon'] = lat_lon['lon'].iloc[i]\n",
    "    # concat the data\n",
    "    result = pd.concat([result, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'event_count_battles', 'event_count_explosions',\n",
       "       'event_count_violence', 'fatalities_battles', 'fatalities_explosions',\n",
       "       'fatalities_violence', 'GOSIF_GPP', 'rainfall_chirps', 'GOSIF_GPP_SD',\n",
       "       'elevation', 'soil', 'lon', 'lat', 'temperature_2m_mean',\n",
       "       'temperature_2m_mean_sd', 'shortwave_radiation_sum',\n",
       "       'shortwave_radiation_sum_sd', 'precipitation_sum',\n",
       "       'precipitation_sum_sd', 'nearest_neighbor_distance_x', 'market_lat',\n",
       "       'market_lon', 'price_index', 'estimated_population', 'title',\n",
       "       'overall_phase', 'country', 'phase3_worse_population',\n",
       "       'phase3_worse_percentage', 'phase1_population', 'phase1_percent',\n",
       "       'phase2_population', 'phase2_percent', 'phase3_population',\n",
       "       'phase3_percent', 'phase4_population', 'phase4_percent',\n",
       "       'phase5_population', 'phase5_percent', 'phase3_worse_percentage_manual',\n",
       "       'phase3_plus_phase4', 'phase2_worse_percentage_manual',\n",
       "       'phase2_plus_phase3', 'phase2_plus_phase3_plus_phase4',\n",
       "       'soil_moisture_0_to_7cm_mean', 'soil_moisture_0_to_7cm_sd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df and result on lat and lon, add indicator\n",
    "new_df = df.merge(result, how='left', on=['lat', 'lon'], indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_merge\n",
      "left_only         0\n",
      "right_only        0\n",
      "both          38776\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# see merge result\n",
    "print(new_df.groupby('_merge').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop _merge\n",
    "new_df.drop('_merge', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "new_df.to_csv('merge_complete_elevation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
