{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 421/421 [01:27<00:00,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "# read xlsx file\n",
    "df = pd.read_excel(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\0.external_data\\FAO_price_data\\FAO_DATA_FOR_MIGUEL.xlsx')\n",
    "\n",
    "new_df = df[['long', 'lat']]\n",
    "\n",
    "# remove duplicates\n",
    "new_df = new_df.drop_duplicates()\n",
    "#reset index\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "# make API request based on Longtiude and Latitude\n",
    "\n",
    "\n",
    "for i in tqdm.tqdm(range(len(new_df))):\n",
    "    url = 'https://api.opentopodata.org/v1/aster30m?locations={},{}'.format(new_df['lat'][i], new_df['long'][i])\n",
    "    response = requests.get(url)\n",
    "    data = json.loads(response.text)\n",
    "    # create a new column to store the elevation data\n",
    "    if 'results' in data:\n",
    "        new_df.loc[i, 'elevation'] = data['results'][0]['elevation']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/421 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m    data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n\u001b[0;32m      5\u001b[0m    \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m data:\n\u001b[1;32m----> 6\u001b[0m       new_df\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39msoil\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mproperties\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mdepths\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[39m# merge the elevation data with the original dataframe\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(df, new_df, on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mlong\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m'\u001b[39m], how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(len(new_df))):\n",
    "   url = 'https://rest.isric.org/soilgrids/v2.0/properties/query?lon={}&lat={}&property=bdod&depth=0-5cm&value=mean'.format(new_df['long'][i], new_df['lat'][i])\n",
    "   response = requests.get(url)\n",
    "   data = json.loads(response.text)\n",
    "   if 'properties' in data:\n",
    "      new_df.loc[i, 'soil'] = data['properties']['layers'][0]['depths'][0]['values']['mean']\n",
    "\n",
    "# merge the elevation data with the original dataframe\n",
    "df = pd.merge(df, new_df, on=['long', 'lat'], how='left')\n",
    "#remove elevation_x and rename elevation_y to elevation\n",
    "df = df.drop(['elevation_x'], axis=1)\n",
    "df = df.rename(columns={'elevation_y': 'elevation'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the merged dataframe to a csv file\n",
    "df.to_csv(r'C:\\Users\\WeilunShi\\OneDrive - CGIAR\\Desktop\\Food Crisis and Insecurity\\\\2.merge_data\\FAO_elevation_soil.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Food_Crisis_and_Insecurity-8fC6jjVv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
